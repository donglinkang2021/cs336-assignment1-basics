# Changelog

## [0.0.3] - 20250925

- [code] pass all the test cases in `tests/test_model.py`
- [code] transformer LM, pass `test_transformer_lm`
- [code] transformer block, pass `test_transformer_block`
- [code] softmax, scaled_dot_product_attention, multihead_self_attention, pass the test cases
- [code] rope, pass `test_rope`
- [code] swiglu FFN layer, pass `test_swiglu`
- [code] rmsnorm layer, pass `test_rmsnorm`
- [code] linear/embedding layer, pass `test_linear/test_embedding`

### Record

ç»ˆäºå…¨éƒ¨éƒ½è¿‡äº†ï¼Œè‡ªå·±åœ¨Attentionéƒ¨åˆ†å‚è€ƒ`nanovllm`çš„`qwen3`å†™æ³•æ¥å†™é›†æˆçš„rope -> [here](https://github.com/GeeeekExplorer/nano-vllm/blob/main/nanovllm/models/qwen3.py#L53)ï¼Œç›®å‰ç»“æœå¦‚ä¸‹ï¼š

```bash
(cs336-basics) [root:assignment1-basics]$ uv run pytest tests/test_model.py
============================== test session starts ==============================
tests/test_model.py::test_linear PASSED
tests/test_model.py::test_embedding PASSED
tests/test_model.py::test_swiglu PASSED
tests/test_model.py::test_scaled_dot_product_attention PASSED
tests/test_model.py::test_4d_scaled_dot_product_attention PASSED
tests/test_model.py::test_multihead_self_attention PASSED
tests/test_model.py::test_multihead_self_attention_with_rope PASSED
tests/test_model.py::test_transformer_lm PASSED
tests/test_model.py::test_transformer_lm_truncated_input PASSED
tests/test_model.py::test_transformer_block PASSED
tests/test_model.py::test_rmsnorm PASSED
tests/test_model.py::test_rope PASSED
tests/test_model.py::test_silu_matches_pytorch PASSED
============================== 13 passed in 2.28s ===============================
```

## [0.0.2] - 20250924

- [code] tokenizer, pass the `tests/test_tokenizer.py`
- [code] pre-tokenization + multiprocessing, pass the `tests/train_bpe.py`
- [code] pre-tokenization, use `regex.split` and `regex.finditer` to handle special tokens and pre-tokenization, make it to ` 2.282496929168701 < 1.5`, but still too slow

### Record

çœ‹äº†ä¸€ä¸‹ `gpt2_bytes_to_unicode` çš„å®ç°ï¼Œä»–çš„ä¸»è¦åŸç†å°±æ˜¯æŠŠ 0-255ä¸­çš„ unprintable çš„å­—ç¬¦å…¨éƒ¨å»æ‰ï¼Œå°†å¯ä»¥æ‰“å°çš„ 0-255 çš„å­—ç¬¦å…¨éƒ¨æ”¾åœ¨å‰é¢ä»0å¼€å§‹ç¼–ç ï¼ˆä¸€å…±188ä¸ªå¯æ‰“å°çš„ï¼‰ï¼Œåé¢çš„68ä¸ªå­—ç¬¦å°±æŠŠ 256+i çš„ç¼–ç å¡åˆ°å‰é¢å»ï¼›

å…³äºtokenizerçš„åŸºæœ¬å…¨è¿‡äº†ï¼Œç¬¬ä¸€ä¸ªtrain_bpeçš„éƒ¨åˆ†å€Ÿé‰´äº†csdnä¸Šä¸€ä½è€å“¥çš„ä»£ç [here](refer: https://blog.csdn.net/Bug_makerACE/article/details/149248369)ï¼Œç¬¬äºŒéƒ¨åˆ†æ›´å¤šæ˜¯å‚è€ƒäº†karpathyçš„minbpe/regexé‚£çš„å®ç°æ¥ä¼˜åŒ–encodeçš„é€Ÿåº¦ ğŸ‘‰ [karpathy/minbpe](https://github.com/karpathy/minbpe)ï¼›

ç›®å‰ç»“æœå¦‚ä¸‹ï¼š

```bash
(cs336-basics) [root:assignment1-basics]$ uv run pytest tests/test_train_bpe.py 
============================== test session starts ==============================
tests/test_train_bpe.py::test_train_bpe_speed PASSED
tests/test_train_bpe.py::test_train_bpe PASSED
tests/test_train_bpe.py::test_train_bpe_special_tokens PASSED
============================== 3 passed in 21.30s ===============================
(cs336-basics) [root:assignment1-basics]$ uv run pytest tests/test_tokenizer.py
============================== test session starts ==============================
tests/test_tokenizer.py::test_roundtrip_empty PASSED
tests/test_tokenizer.py::test_empty_matches_tiktoken PASSED
...
tests/test_tokenizer.py::test_encode_iterable_memory_usage PASSED
tests/test_tokenizer.py::test_encode_memory_usage XFAIL (Tokenizer.encode is expected to take more memory than allotted (1MB).)
======================== 24 passed, 1 xfailed in 14.16s =========================
```

## [0.0.1] - 20250923

- [code] implement the simple version of bpe refer to the minbpe of karpathy, but fail 3/3 cases
- [handout] bpe tokenizer training

### Record

å¼€å§‹æ­£å¼çœ‹äº†ä¸€ä¸‹è¿™ä¸ªrepo, è¿è¡Œä¸‹é¢çš„ä»£ç çœ‹çœ‹æ•ˆæœ

```bash
uv run pytest
```

```bash
=============================== short test summary info ================================
FAILED tests/test_data.py::test_get_batch - NotImplementedError
FAILED tests/test_model.py::test_linear - NotImplementedError
...
======================= 47 failed, 1 xfailed in 86.94s (0:01:26) =======================
```

æµ‹è¯•äº†ä¸€ä¸‹å‘ç°å¤ªæ…¢äº†ï¼Œé—®äº†geminiå¯ä»¥å…ˆæµ‹è¯•æŸéƒ¨åˆ† --> [éƒ¨åˆ†æµ‹è¯•åŠ å¿«é€Ÿåº¦](../tips/éƒ¨åˆ†æµ‹è¯•åŠ å¿«é€Ÿåº¦.md)
